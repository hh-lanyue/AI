# 深度学习、目标检测

## 一、目标检测基础知识

### 1 目标检测问题定义

==目标检测==是在图片中对可变数量的目标进行==查找==和==分类==，即==目标位置定位==与==目标类别分类==

- 目标种类与数量问题
- 目标尺度问题
- 外在环境干扰问题

![image-20230218154019960](./assets/image-20230218154019960.png)

### 2 图像分类、目标分割、目标检测

==目标检测==：确定目标在给定图像中的位置，如目标定位，以及每个目标属于哪个类别，即目标分类

![image-20230218173718294](./assets/image-20230218173718294.png)

==图像分类==：对图像中特定对象的类别进行分类或预测的技术，该技术的主要目的是准确识别图像中的特征

![image-20230218173748115](./assets/image-20230218173748115.png)

==目标分割==：需要找到当前的目标所占的区域（==语义分割==：同一类目标所占区域，==实例分割==：不仅要区分不同**语义**层面上的目标，而且对于同一类别的目标，也要划分出不同的**实例**）

**传统的机器学习方法中会手动设置一些特征来完成特征提取，深度学习中通常通过卷积神经网络完成特征的抽取**。目标检测和图像分类都属于计算机视觉领域比较基础的应用

![image-20230218173632442](./assets/image-20230218173632442.png)

### 3 目标检测方法的变迁

![mbjcsf](./assets/img.webp)

![img](./assets/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1hESDE5OTEwMTEz,size_16,color_FFFFFF,t_70.png)

### 4 目标检测算法的基本流程

![image-20230218202502260](./assets/image-20230218202502260.png)

#### 传统目标检测算法

- Viola-Jones（人脸检测）
- HOG+SVM
- DPM（==传统目标检测算法的巅峰之作==）

> # Viola-Jones（人脸检测）
>
> ![image-20230226105701121](./assets/image-20230226105701121.png)
>
> ## 第一步 Haar 特征提取
>
> ### 概念
>
> Haar特征分为三类：==边缘特征==、==线性特征==、==中心特征和对角线特征==，它们组合成特征模板，**特征模板内有白色和黑色两种矩形**。并定义该模板的==特征值为白色矩形像素和减去黑色矩形像素和==。
>
> Haar特征值反映了图像的灰度变化情况。例如：脸部的一些特征能由矩形特征简单的描述，如：眼睛要比脸颊颜色要深，鼻梁两侧比鼻梁颜色要深，嘴巴比周围颜色要深等。
>
> 但==矩形特征只对一些简单的图形结构，如边缘、线段较敏感==，所以只能描述特定走向（水平、垂直、对角）的结构。
>
> ### 分类
>
> ![image-20230312150303983](./assets/image-20230312150303983.png)
>
> ### 提取特征
>
> 从上到下,从左到右
>
> ![img](./assets/webp.webp)
>
> #### 1 滑动
>
> 存在某一图片,大小为100x100;Haar特征模板大小为10x10,步长为10，如果要提取图片所有Haar特征,需要滑动100次,即会产生100个Haar模板,这样就会计算100次特征
>
> ![image-20230316200156084](./assets/image-20230316200156084.png)
>
> #### 2 缩放
>
> 在滑动遍历完成后会进行缩放遍历,模板会由10x10缩放为11x11,之后继续滑动遍历,直到模板缩放到20x20,缩放10次
>
> 事实上，矩形特征值是由==矩形模版类别==、==矩形位置==和==矩形大小==这三个因素的函数。因此当特征模板的大小和类别也发生变化的时候，一个图像得到的特征值的数量要暴增，一般的Haar特征计算过程即是如此，一张图像，经过不同的模板滑动，不同模板的不同大小的矩形的滑动，可以得到N个特征值，但是对于一般的Haar分类器来讲，特征计算只是一个小步骤，最终要经过某种算法比如==AdaBoost算法==来进行训练，以判别哪些矩形的特征是对分类器分类最有效的**，**通过计算Haar特征的特征值，可以有将图像矩阵映射为1维特征值，有效实现了降维
>
> ### 计算特征
>
> 一张图像能够提取出多少个Haar-like特征？矩形特征可位于图像窗口的任意位置，其大小也可以任意改变，所以矩形特征值是矩**形模版类别**、**矩形位置**和**矩形大小**这三个因素的函数
>
> 以一个 24 × 24 的窗口为例，采用5种Haar-like特征进行计算
>
> ![image-20230318124236892](./assets/image-20230318124236892.png)
>
> ![image-20230318124123458](./assets/image-20230318124123458.png)
>
> #### a 矩形特征图
>
> 该矩形特征的行高可以为1~24中的任意一个数，但列宽只能是2的倍数，即1-24中的偶数；行高与列宽两两组合：矩形模板的大小
>
> ![image-20230318124803391](./assets/image-20230318124803391.png)
>
> 以上只考虑了矩形模板的类别与大小，并没有考虑位置，假设矩形模板大小为：1 x 2，则它在 24 × 24 的图像窗口中有多少不同位置呢？行高为1，所以有24-**1**+1=24种可能；列宽为2，所以有24-**2**+1=23种可能，所以，该矩形模板有24 × 23 = 552 种不同的位置
>
> ![image-20230318130921369](./assets/image-20230318130921369.png)
> $$
> 如果一个矩形模板的大小为 \quad x*y \quad 则可产生的特征数为
> \\(W-x+1)*(H-y+1)
> \\W为图像窗口的列宽，H为图像窗口的行高
> \\x为矩形模板的列宽，h为矩形模板的行高
> $$
>
> #### b、c、d、e 特征图
>
> - 假设矩形模板大小为：1 × 2，则该矩形模板有 24 × 23 = 552 种可能的位置
> - 假设矩形模板大小为：1 × 4，则该矩形模板有 24 × 21 = 504 种可能的位置
> - ......
> - 假设矩形模板大小为：2 × 6，则该矩形模板有 23 × 19 = 437 种可能的位置.
> - ......
> - 假设矩形模板大小为：24 × 24，则该矩形模板有1 × 1 = 1 种可能的位置
>
> 通过程序计算可知 a、b、c、d、e 这五种特征模板的特征值数量分别为：43200，43200，27600，27600，20736，总计为160381. 就单单24 × 24 大小的图像窗口就有16万以上的特征值，这特征值数量有点多，计算量确实有点大
>
> ### 积分图
>
> 图像是由一系列的离散像素点组成, 因此图像的积分其实就是求和。积分图又称总和面积. ==对于一幅灰度图==，积分图像中的==任意一点的值==是指==从原图像的左上角到这个点所构成的矩形区域内的所有点的灰度值之和==
>
> ![image-20230318132426011](./assets/image-20230318132426011.png)
>
> #### 积分图计算原理
>
> 图像是由一系列的离散像素点组成, 因此图像的积分其实就是求和. 图像积分图中每个点的值是原图像中该点左上角的所有像素值之和，首先建立一个数组 A 作为积分图像，其宽高与原图像相等. 然后对这个数组赋值，每个点存储的是该点与图像原点所构成的矩形中所有像素的和
> $$
> SAT(x,y)=\sum_{i = 1,j = 1}^{i=x,j=y} (i,j)点的像素值
> $$
> ![image-20230318154237077](./assets/image-20230318154237077.png)
>
> #### 使用积分图==快速==的计算特征
>
> ![image-20230318155023506](./assets/image-20230318155023506.png)
>
> ## 第二步 Adaboost 算法 根据特征训练分类器
>
> ### 步骤一 计算特征值
>
> 先选一种类型特征 ， 比如选模板 X2 ， 尺寸 6 * 6 ， 在图片位置 （ 4 ， 5 ） 求出的各个训练图片的 Haar-like 值为特征值 
>
> ![image-20230316203547659](./assets/image-20230316203547659.png)
>
> ### 步骤二 得到弱分类器函数
>
> 输入训练图片 （ 20000 张人脸 ， 40000 张非人脸 ， 尺寸 20 * 20 ） ． 这样的话每个训练图片都得到一个整数的特征值 。 为简单示例 ， 假设 3 张人脸 ， 3 张非人脸 。 得到值以后排序后如下 
>
> ![image-20230316202758514](./assets/image-20230316202758514.png)
>
> 对于这样的训练数据，我们选一个最简单的分类函数（Adaboost里叫作==弱分类器函数==）：
>
> - 特征值小于等于某个==阈值t1==就认为是人脸，大于==阈值==就是非人脸
> - 特征值小于等于某个==阈值t1==就认为是人非脸，大于==阈值==就是人脸
>
> 这里的t1一般选具体的某个特征值，是个常数；至于选小于等于还是大于等于就看这样选择后的==错误率哪个更低==，需要由输入训练数据后根据错误率来得到的值
>
> ### 如何求 ==阈值t1==?
>
> 最初的弱分类器可能只是一个最基本的Haar-like特征，计算输入图像的Haar-like特征值，和最初的弱分类器的特征值比较，来判断输入图像是否为人脸，然而这个弱分类器太简陋了，可能不比随机判断的效果好
>
> 对弱分类器的孵化就是训练弱分类器为==最优分类器==，注意这是的最优==不是强分类器==，只是一个误差相对我稍低的弱分类器，训练弱分类器实际上是为分类器进行设置的过程，弱分类器的数学结构：
> $$
> \\
> 弱分类器
> \\
> h(x,f,p,\theta)=
> \left\{ 
>     \begin{array}{c}
>         p(f_x)<\theta \quad \quad =1 \\ 
>         其他   \quad \quad =0 \\ 
>     \end{array}
> \right.
> \\
> \\ f 为特征
> \\ \theta 为阈值
> \\ p指示控制不等号的方向
> \\ x表一个检测子窗口
> $$
> 最基本的弱分类器只包含一个Haar-like特征，也就是说决策树只有一层，被称为树桩(stump)，要比较输入图像的特征值和弱分类器特征，需要一个阈值，当输入图像的特征值大于该阈值时判定其为人脸
>
> 训练最优弱分类器的过程其实就是在==寻找合适的分类器阈值==，使该分类器对所有样本的判断误差最低
>
> #### 第一轮迭代
>
> 因为这是第一轮迭代计算，上面的每个训练样本赋值初始化权重 w1 =（0.167, 0.167, 0.167, 0.167, 0.167, 0.167）也就是样本数量分之一为初始权值
>
> $$
> 初始权值
> \\
> w_1=\frac{1}{6} = 1.167
> $$
> ![image-20230316202758514](./assets/image-20230316202758514.png)
>
> 从表中数据我们知道t1可以=100、110、120、130、140、150
>
> 若按 t1=100，选x < =100方式比较好，此时错判2个，错误率e=2 * 0.167 = 0.334
>
> ![image-20230316213107605](./assets/image-20230316213107605.png)
>
> 若按 t1=110，选x < =110方式比较好，此时错判1个，错误率rate=1 * 0.167 = 0.167
>
> ![image-20230316213428932](./assets/image-20230316213428932.png)
>
> 若按 t1=120，选x < =120方式比较好，此时错判2个，错误率e=2 * 0.167 = 0.334
>
> 同理 t1=130，此时错判3个，错误率e=3 * 0.167 = 0.501
>
> 同理 t1=140，此时错判2个，错误率e=2 * 0.167 = 0.334
>
> 同理 t1=150，...
>
> 可见 ==t1=110时，选x < =110，错误率最小rate=0.167==，则 
>
> $$
> 本次迭代的 \quad最优弱分类器函数 \quad 为
> \\
> y=f_{1}(x)=
> \left\{ 
>     \begin{array}{c}
>         x<=110 \quad \quad =1 \\ 
>         \quad x=其他   \quad \quad =-1 \\ 
>     \end{array}
> \right.
> \\
> \\
> 函数f1的权重
> \\
> f_{w1}=\frac{1}{2} \ln \frac{1-rate}{rate} =0.5 * ln((1 – 0.167) / 0.167) = 0.8047
> $$
>
> #### 第二轮迭代
>
> ##### 更新样本权重
>
> 在上一次迭代中我们选了 t1=110，测试样本中只有特征值是 140 的测试是误判的，其他都是正确，正确的样本是：100, 110, 120, 130, 150
>
> 因为上次迭代是第一次迭代，所以权重都是0.167，这次是第二次迭代，所以这次样本权重调整方式为：
> $$
> w_2=w_1*e^{-f_{w1}}=\frac{1}{6}*e^{-\frac{1}{2}ln\frac{1-rate}{rate}}=\frac{1}{6}*\frac{1}{\sqrt{5}} \approx 0.075
> $$
> 
>
> ### 训练最优弱分类器

#### 深度学习目标检测算法

One-stage（YOLO 和 SSD系列）：通过直接回归目标位置的策略来进行目标的检测和定位

Two-stage（Faster RCNN系列）：通过利用RPN网络对候选区域进行推荐

### 5 深度学习目标检测的方法

![image-20230219100459070](./assets/image-20230219100459070.png)



### 6 传统目标检测算法和深度学习目标检测算法的区别

![image-20230219101222101](./assets/image-20230219101222101.png)

### 7 目标检测算法的应用场景

- 人脸识别
- OCR文本识别
- 通用物体识别
- 行车检测

### 8 传统目标检测算法流程

![image-20230219105211901](./assets/image-20230219105211901.png)



